
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>30-reinforcement-learning -  Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.2">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    
    <link rel="prev" href="29-inceptionism.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Sections
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="2-neural-networks-intro.html">
            
                <a href="2-neural-networks-intro.html">
            
                    
                    2-neural-networks-intro - Neural Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="3-three-reasons-to-use-deep-learning.html">
            
                <a href="3-three-reasons-to-use-deep-learning.html">
            
                    
                    3-three-reasons-to-use-deep-learning - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="4-choosing-deep-net.html">
            
                <a href="4-choosing-deep-net.html">
            
                    
                    4-choosing-deep-net - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="5-history-of-deep-nets.html">
            
                <a href="5-history-of-deep-nets.html">
            
                    
                    5-history-of-deep-nets - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="6-restricted-boltzmann-machines.html">
            
                <a href="6-restricted-boltzmann-machines.html">
            
                    
                    6-restricted-boltzmann-machines - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="7-deep-belief-networks.html">
            
                <a href="7-deep-belief-networks.html">
            
                    
                    7-deep-belief-networks - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="8-convolutional-neural-networks.html">
            
                <a href="8-convolutional-neural-networks.html">
            
                    
                    8-convolutional-neural-networks - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="9-recurrent-neural-networks.html">
            
                <a href="9-recurrent-neural-networks.html">
            
                    
                    9-recurrent-neural-networks - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.9" data-path="10-autoencoders.html">
            
                <a href="10-autoencoders.html">
            
                    
                    10-autoencoders - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.10" data-path="11-recursive-neural-tensor-nets.html">
            
                <a href="11-recursive-neural-tensor-nets.html">
            
                    
                    11-recursive-neural-tensor-nets - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.11" data-path="12-deep-learning-use-cases.html">
            
                <a href="12-deep-learning-use-cases.html">
            
                    
                    12-deep-learning-use-cases - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.12" data-path="13-deep-network-platform.html">
            
                <a href="13-deep-network-platform.html">
            
                    
                    13-deep-network-platform - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.13" data-path="14-platforms-h2o-ai.html">
            
                <a href="14-platforms-h2o-ai.html">
            
                    
                    14-platforms-h2o-ai - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.14" data-path="15-platforms-dato-graphlab.html">
            
                <a href="15-platforms-dato-graphlab.html">
            
                    
                    15-platforms-dato-graphlab - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.15" data-path="16-intro-deep-learning-libraries.html">
            
                <a href="16-intro-deep-learning-libraries.html">
            
                    
                    16-intro-deep-learning-libraries - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.16" data-path="17-deep-library-theano.html">
            
                <a href="17-deep-library-theano.html">
            
                    
                    17-deep-library-theano - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.17" data-path="18-deep-library-deeplearning4j.html">
            
                <a href="18-deep-library-deeplearning4j.html">
            
                    
                    18-deep-library-deeplearning4j - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.18" data-path="19-deep-library-torch.html">
            
                <a href="19-deep-library-torch.html">
            
                    
                    19-deep-library-torch - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.19" data-path="20-deep-library-caffe.html">
            
                <a href="20-deep-library-caffe.html">
            
                    
                    20-deep-library-caffe - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.20" data-path="21-optimizing-your-fit.html">
            
                <a href="21-optimizing-your-fit.html">
            
                    
                    21-optimizing-your-fit - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.21" data-path="22-tensorflow.html">
            
                <a href="22-tensorflow.html">
            
                    
                    22-tensorflow - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.22" data-path="23-metrics-for-deep-learning.html">
            
                <a href="23-metrics-for-deep-learning.html">
            
                    
                    23-metrics-for-deep-learning - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.23" data-path="24-deep-network-performance.html">
            
                <a href="24-deep-network-performance.html">
            
                    
                    24-deep-network-performance - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.24" data-path="25-text-analytics.html">
            
                <a href="25-text-analytics.html">
            
                    
                    25-text-analytics - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.25" data-path="26-configuring-a-deep-net.html">
            
                <a href="26-configuring-a-deep-net.html">
            
                    
                    26-configuring-a-deep-net - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.26" data-path="27-transfer-learning.html">
            
                <a href="27-transfer-learning.html">
            
                    
                    27-transfer-learning - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.27" data-path="28-neural-storyteller.html">
            
                <a href="28-neural-storyteller.html">
            
                    
                    28-neural-storyteller - 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.28" data-path="29-inceptionism.html">
            
                <a href="29-inceptionism.html">
            
                    
                    29-inceptionism - 
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.29" data-path="30-reinforcement-learning.html">
            
                <a href="30-reinforcement-learning.html">
            
                    
                    30-reinforcement-learning - 
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >30-reinforcement-learning - </a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="reinforcement-learning">Reinforcement Learning</h1>
<p>Computers that can play games are always a hot topic.</p>
<p>In December 2013, Deepmind released a groundbreaking paper called &quot;Playing Atari with Deep Reinforcement Learning&quot;.</p>
<p>A little over a month later, Google announced they bought deep mind for a big sum of money.</p>
<p>Since then there has been a lot of talk about reinforcement learning in the field of AI.</p>
<p>In January 2016, alphago was able to beat the world champion.</p>
<h2 id="history">History</h2>
<p>The history of RL goes all the way back to AI, animal psychology, and control theory. </p>
<p>At the heart of it, it involves an autonomous agent like a person, learning to navigate an uncertain environment with the objective of maximizing a numerical reward.</p>
<p>Sports are a great example of this. </p>
<p>In a tennis game, the player needs to review his actions available, and choose one as it will change the state of the game.</p>
<p>Every action is performed with a rewarding in mind: trying to get a point to win the set/game/match.</p>
<p>The agent needs to follow a set of rules and strategies in order to maximize the score.</p>
<h2 id="model">Model</h2>
<p>However if you&apos;re building an autonomous agent how woudl you model this?</p>
<p>We know that the agent&apos;s actions will change the state of the environment, so a model would need to take a state and an action as input, and generate the maximum expected reward as output.</p>
<p>However, because that would only take you to the next state, the model needs to take into consideration the total expected reward for every action from the current until the end state.</p>
<p>The way this works is different for each application.</p>
<p>Building a tennis agent is different than building an Atari agent.</p>
<h2 id="deep-atari">Deep Atari</h2>
<p>The researchers at deep mind use a series of Atari screenshots to build a CNN with a couple of tweaks.</p>
<p>The output isn&apos;t a class  - but instead a target number for the maximum reward.</p>
<p>So it was actually dealing <strong>with regression</strong>, not classification.</p>
<p>They also <strong>didn&apos;t use pooling layers</strong>, since unlike image recognition, individual positions of game objects like the player are important and can&apos;t be reduced.</p>
<p>A recurrent network could be used too, as long as the output layer was tailored for regression, and the input at each timestep included the action and the environment state.</p>
<h2 id="deep-q-network">Deep Q Network</h2>
<p>There is also the Deep Q Network, or DQN.</p>
<p>It also uses the principles of predicting the maximum reward given a state and an action. </p>
<p>It was <strong>patented by google</strong>, and it has seen a lot of improvements like the experience replay, and the dooling network architecture.</p>
<h2 id="supervised-learning">Supervised learning</h2>
<p>Reinforcement learning isn&apos;t just a fancy way to say &quot;Supervised learning&quot;.</p>
<p>Supervised learning is all about making sense of the environment based on historical examples.</p>
<p>However, that is not always the best way of doing things.</p>
<p>Imagine if you&apos;re trying to drive a car in heavy traffic based on the road patterns you observed the week before where the roads where clear. Or like driving only looking at the rear-look mirror.</p>
<p>Reinforcement learning is all about reward. You get points for your actions, like staying in your lane, signalling when you need to.</p>
<p>You can also lose points for dangerous actions like tailgating and speeding.</p>
<p>The objective is to get the maximum number of points possible given the current state of the traffic on the road around you.</p>
<p>Reinforcement learning emphasises that an action results in a change in the state which supervised learning doesn&apos;t focus on.</p>
<h2 id="exploration-vs-exploitation">Exploration vs Exploitation</h2>
<p>In April 2016 Jeff BEzoz said how amazon is great to fail and most companies cannot go through failed experiments.</p>
<p>Most organizations are used to operate in the realms of conventional wisdom, which is about exploiting what is known to achieve finite rewards with known odds.</p>
<p>Some groups venture into the unknown and explore new territory, looking for rewards. Many organizations fail, but some succeed and change the world.</p>
<p>With reinforcement learning, an agent can explore the tradeoff between exploration and exploitation, and choose the path to the maximum expected reward.</p>
<h2 id="global-approach">Global Approach</h2>
<p>Deep Reinforcement learning falls in the broader umbrella of AI, and between Deep Learning and Reinforcement learning.</p>
<p>It involves topics like goal setting, planning and perception.</p>
<p>And it can build a link between AI and engineering disciplines.</p>
<h2 id="relevant-urls">Relevant URLs</h2>
<ul>
<li>Richard Sutton book: <a href="https://webdocs.cs.ualberta.ca/~sutto" target="_blank">https://webdocs.cs.ualberta.ca/~sutto</a>...</li>
<li>Tambet Matiisen post: <a href="https://www.nervanasys.com/demystifyi" target="_blank">https://www.nervanasys.com/demystifyi</a>...</li>
<li>Andrej Karpathy post: <a href="http://karpathy.github.io/2016/05/31/rl/" target="_blank">http://karpathy.github.io/2016/05/31/rl/</a></li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="29-inceptionism.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page: 29-inceptionism - ">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"30-reinforcement-learning - ","level":"1.2.29","depth":2,"previous":{"title":"29-inceptionism - ","level":"1.2.28","depth":2,"path":"sections/29-inceptionism.md","ref":"sections/29-inceptionism.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"sections/30-reinforcement-learning.md","mtime":"2017-01-23T19:10:40.000Z","type":"markdown"},"gitbook":{"version":"3.2.2","time":"2017-06-10T19:24:51.993Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

